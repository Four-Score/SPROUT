{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ! pip install trulens_eval llama_index ftfy regex tqdm git+https://github.com/openai/CLIP.git torch torchvision matplotlib scikit-image qdrant_client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pdfplumber in c:\\users\\dt\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (0.10.2)\n",
      "Requirement already satisfied: pdfminer.six==20221105 in c:\\users\\dt\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from pdfplumber) (20221105)\n",
      "Requirement already satisfied: Pillow>=9.1 in c:\\users\\dt\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from pdfplumber) (10.1.0)\n",
      "Requirement already satisfied: pypdfium2>=4.18.0 in c:\\users\\dt\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from pdfplumber) (4.21.0)\n",
      "Requirement already satisfied: charset-normalizer>=2.0.0 in c:\\users\\dt\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from pdfminer.six==20221105->pdfplumber) (3.2.0)\n",
      "Requirement already satisfied: cryptography>=36.0.0 in c:\\users\\dt\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from pdfminer.six==20221105->pdfplumber) (41.0.4)\n",
      "Requirement already satisfied: cffi>=1.12 in c:\\users\\dt\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from cryptography>=36.0.0->pdfminer.six==20221105->pdfplumber) (1.15.1)\n",
      "Requirement already satisfied: pycparser in c:\\users\\dt\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from cffi>=1.12->cryptography>=36.0.0->pdfminer.six==20221105->pdfplumber) (2.21)\n"
     ]
    }
   ],
   "source": [
    "!pip install pdfplumber"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pdfplumber\n",
    "from llama_index import Document"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from llama_index.multi_modal_llms.generic_utils import (\n",
    "    load_image_urls,\n",
    ")\n",
    "from llama_index import SimpleDirectoryReader, Document\n",
    "\n",
    "# context images\n",
    "image_path = \"nvdi-images\"\n",
    "image_documents = SimpleDirectoryReader(image_path).load_data()\n",
    "\n",
    "# Function to extract text from a single PDF\n",
    "def extract_text_from_pdf(pdf_path):\n",
    "    with pdfplumber.open(pdf_path) as pdf:\n",
    "        text = ''\n",
    "        for page in pdf.pages:\n",
    "            text += page.extract_text() + ' '  # Extract text from each page\n",
    "        return text\n",
    "\n",
    "# Get a list of PDF file paths from the directory\n",
    "def get_pdf_file_paths(directory):\n",
    "    return [os.path.join(directory, f) for f in os.listdir(directory) if f.endswith('.pdf')]\n",
    "\n",
    "# Your directory containing PDFs\n",
    "pdf_directory = 'NDVI-analysis'\n",
    "\n",
    "# Get the list of PDF file paths\n",
    "pdf_file_paths = get_pdf_file_paths(pdf_directory)\n",
    "\n",
    "# List to store text documents\n",
    "text_documents = []\n",
    "\n",
    "# Iterate over each PDF file path, extract text, and create a Document object\n",
    "for pdf_path in pdf_file_paths:\n",
    "    pdf_text = extract_text_from_pdf(pdf_path)\n",
    "    # Here you might want to split or process the text as per your requirements\n",
    "    text_documents.append(Document(text=pdf_text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████| 338M/338M [08:38<00:00, 683kiB/s]\n"
     ]
    },
    {
     "ename": "RateLimitError",
     "evalue": "Error code: 429 - {'error': {'message': 'You exceeded your current quota, please check your plan and billing details.', 'type': 'insufficient_quota', 'param': None, 'code': 'insufficient_quota'}}",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRateLimitError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\dt\\Desktop\\Ayesha\\SPROUT\\multimodalsearch.ipynb Cell 6\u001b[0m line \u001b[0;36m8\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/dt/Desktop/Ayesha/SPROUT/multimodalsearch.ipynb#W5sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m image_nodes \u001b[39m=\u001b[39m node_parser\u001b[39m.\u001b[39mget_nodes_from_documents(image_documents)\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/dt/Desktop/Ayesha/SPROUT/multimodalsearch.ipynb#W5sZmlsZQ%3D%3D?line=5'>6</a>\u001b[0m text_nodes \u001b[39m=\u001b[39m node_parser\u001b[39m.\u001b[39mget_nodes_from_documents(text_documents)\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/dt/Desktop/Ayesha/SPROUT/multimodalsearch.ipynb#W5sZmlsZQ%3D%3D?line=7'>8</a>\u001b[0m asl_index \u001b[39m=\u001b[39m MultiModalVectorStoreIndex(image_nodes \u001b[39m+\u001b[39;49m text_nodes)\n",
      "File \u001b[1;32mc:\\Users\\dt\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\llama_index\\indices\\multi_modal\\base.py:72\u001b[0m, in \u001b[0;36mMultiModalVectorStoreIndex.__init__\u001b[1;34m(self, nodes, index_struct, service_context, storage_context, use_async, store_nodes_override, show_progress, image_vector_store, image_embed_model, is_image_to_text, **kwargs)\u001b[0m\n\u001b[0;32m     68\u001b[0m     storage_context\u001b[39m.\u001b[39madd_vector_store(SimpleVectorStore(), \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mimage_namespace)\n\u001b[0;32m     70\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_image_vector_store \u001b[39m=\u001b[39m storage_context\u001b[39m.\u001b[39mvector_stores[\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mimage_namespace]\n\u001b[1;32m---> 72\u001b[0m \u001b[39msuper\u001b[39;49m()\u001b[39m.\u001b[39;49m\u001b[39m__init__\u001b[39;49m(\n\u001b[0;32m     73\u001b[0m     nodes\u001b[39m=\u001b[39;49mnodes,\n\u001b[0;32m     74\u001b[0m     index_struct\u001b[39m=\u001b[39;49mindex_struct,\n\u001b[0;32m     75\u001b[0m     service_context\u001b[39m=\u001b[39;49mservice_context,\n\u001b[0;32m     76\u001b[0m     storage_context\u001b[39m=\u001b[39;49mstorage_context,\n\u001b[0;32m     77\u001b[0m     show_progress\u001b[39m=\u001b[39;49mshow_progress,\n\u001b[0;32m     78\u001b[0m     use_async\u001b[39m=\u001b[39;49muse_async,\n\u001b[0;32m     79\u001b[0m     store_nodes_override\u001b[39m=\u001b[39;49mstore_nodes_override,\n\u001b[0;32m     80\u001b[0m     \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs,\n\u001b[0;32m     81\u001b[0m )\n",
      "File \u001b[1;32mc:\\Users\\dt\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\llama_index\\indices\\vector_store\\base.py:49\u001b[0m, in \u001b[0;36mVectorStoreIndex.__init__\u001b[1;34m(self, nodes, index_struct, service_context, storage_context, use_async, store_nodes_override, show_progress, **kwargs)\u001b[0m\n\u001b[0;32m     47\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_use_async \u001b[39m=\u001b[39m use_async\n\u001b[0;32m     48\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_store_nodes_override \u001b[39m=\u001b[39m store_nodes_override\n\u001b[1;32m---> 49\u001b[0m \u001b[39msuper\u001b[39;49m()\u001b[39m.\u001b[39;49m\u001b[39m__init__\u001b[39;49m(\n\u001b[0;32m     50\u001b[0m     nodes\u001b[39m=\u001b[39;49mnodes,\n\u001b[0;32m     51\u001b[0m     index_struct\u001b[39m=\u001b[39;49mindex_struct,\n\u001b[0;32m     52\u001b[0m     service_context\u001b[39m=\u001b[39;49mservice_context,\n\u001b[0;32m     53\u001b[0m     storage_context\u001b[39m=\u001b[39;49mstorage_context,\n\u001b[0;32m     54\u001b[0m     show_progress\u001b[39m=\u001b[39;49mshow_progress,\n\u001b[0;32m     55\u001b[0m     \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs,\n\u001b[0;32m     56\u001b[0m )\n",
      "File \u001b[1;32mc:\\Users\\dt\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\llama_index\\indices\\base.py:71\u001b[0m, in \u001b[0;36mBaseIndex.__init__\u001b[1;34m(self, nodes, index_struct, storage_context, service_context, show_progress, **kwargs)\u001b[0m\n\u001b[0;32m     69\u001b[0m \u001b[39mif\u001b[39;00m index_struct \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m     70\u001b[0m     \u001b[39massert\u001b[39;00m nodes \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m---> 71\u001b[0m     index_struct \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mbuild_index_from_nodes(nodes)\n\u001b[0;32m     72\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_index_struct \u001b[39m=\u001b[39m index_struct\n\u001b[0;32m     73\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_storage_context\u001b[39m.\u001b[39mindex_store\u001b[39m.\u001b[39madd_index_struct(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_index_struct)\n",
      "File \u001b[1;32mc:\\Users\\dt\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\llama_index\\indices\\vector_store\\base.py:255\u001b[0m, in \u001b[0;36mVectorStoreIndex.build_index_from_nodes\u001b[1;34m(self, nodes, **insert_kwargs)\u001b[0m\n\u001b[0;32m    244\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mbuild_index_from_nodes\u001b[39m(\n\u001b[0;32m    245\u001b[0m     \u001b[39mself\u001b[39m,\n\u001b[0;32m    246\u001b[0m     nodes: Sequence[BaseNode],\n\u001b[0;32m    247\u001b[0m     \u001b[39m*\u001b[39m\u001b[39m*\u001b[39minsert_kwargs: Any,\n\u001b[0;32m    248\u001b[0m ) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m IndexDict:\n\u001b[0;32m    249\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"Build the index from nodes.\u001b[39;00m\n\u001b[0;32m    250\u001b[0m \n\u001b[0;32m    251\u001b[0m \u001b[39m    NOTE: Overrides BaseIndex.build_index_from_nodes.\u001b[39;00m\n\u001b[0;32m    252\u001b[0m \u001b[39m        VectorStoreIndex only stores nodes in document store\u001b[39;00m\n\u001b[0;32m    253\u001b[0m \u001b[39m        if vector store does not store text\u001b[39;00m\n\u001b[0;32m    254\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 255\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_build_index_from_nodes(nodes, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49minsert_kwargs)\n",
      "File \u001b[1;32mc:\\Users\\dt\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\llama_index\\indices\\vector_store\\base.py:236\u001b[0m, in \u001b[0;36mVectorStoreIndex._build_index_from_nodes\u001b[1;34m(self, nodes, **insert_kwargs)\u001b[0m\n\u001b[0;32m    234\u001b[0m     run_async_tasks(tasks)\n\u001b[0;32m    235\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m--> 236\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_add_nodes_to_index(\n\u001b[0;32m    237\u001b[0m         index_struct,\n\u001b[0;32m    238\u001b[0m         nodes,\n\u001b[0;32m    239\u001b[0m         show_progress\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_show_progress,\n\u001b[0;32m    240\u001b[0m         \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49minsert_kwargs,\n\u001b[0;32m    241\u001b[0m     )\n\u001b[0;32m    242\u001b[0m \u001b[39mreturn\u001b[39;00m index_struct\n",
      "File \u001b[1;32mc:\\Users\\dt\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\llama_index\\indices\\multi_modal\\base.py:319\u001b[0m, in \u001b[0;36mMultiModalVectorStoreIndex._add_nodes_to_index\u001b[1;34m(self, index_struct, nodes, show_progress, **insert_kwargs)\u001b[0m\n\u001b[0;32m    316\u001b[0m         text_nodes\u001b[39m.\u001b[39mappend(node)\n\u001b[0;32m    318\u001b[0m \u001b[39m# embed all nodes as text - incclude image nodes that have text attached\u001b[39;00m\n\u001b[1;32m--> 319\u001b[0m text_nodes \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_get_node_with_embedding(\n\u001b[0;32m    320\u001b[0m     text_nodes, show_progress, is_image\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m\n\u001b[0;32m    321\u001b[0m )\n\u001b[0;32m    322\u001b[0m new_text_ids \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mstorage_context\u001b[39m.\u001b[39mvector_stores[DEFAULT_VECTOR_STORE]\u001b[39m.\u001b[39madd(\n\u001b[0;32m    323\u001b[0m     text_nodes, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39minsert_kwargs\n\u001b[0;32m    324\u001b[0m )\n\u001b[0;32m    326\u001b[0m \u001b[39m# embed image nodes as images directly\u001b[39;00m\n\u001b[0;32m    327\u001b[0m \u001b[39m# check if we should use text embedding for images instead of default\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\dt\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\llama_index\\indices\\multi_modal\\base.py:174\u001b[0m, in \u001b[0;36mMultiModalVectorStoreIndex._get_node_with_embedding\u001b[1;34m(self, nodes, show_progress, is_image)\u001b[0m\n\u001b[0;32m    171\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_image_embed_model \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_service_context\u001b[39m.\u001b[39membed_model\n\u001b[0;32m    173\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m--> 174\u001b[0m     id_to_embed_map \u001b[39m=\u001b[39m embed_nodes(\n\u001b[0;32m    175\u001b[0m         nodes,\n\u001b[0;32m    176\u001b[0m         embed_model\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_service_context\u001b[39m.\u001b[39;49membed_model,\n\u001b[0;32m    177\u001b[0m         show_progress\u001b[39m=\u001b[39;49mshow_progress,\n\u001b[0;32m    178\u001b[0m     )\n\u001b[0;32m    180\u001b[0m results \u001b[39m=\u001b[39m []\n\u001b[0;32m    181\u001b[0m \u001b[39mfor\u001b[39;00m node \u001b[39min\u001b[39;00m nodes:\n",
      "File \u001b[1;32mc:\\Users\\dt\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\llama_index\\indices\\utils.py:137\u001b[0m, in \u001b[0;36membed_nodes\u001b[1;34m(nodes, embed_model, show_progress)\u001b[0m\n\u001b[0;32m    134\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    135\u001b[0m         id_to_embed_map[node\u001b[39m.\u001b[39mnode_id] \u001b[39m=\u001b[39m node\u001b[39m.\u001b[39membedding\n\u001b[1;32m--> 137\u001b[0m new_embeddings \u001b[39m=\u001b[39m embed_model\u001b[39m.\u001b[39;49mget_text_embedding_batch(\n\u001b[0;32m    138\u001b[0m     texts_to_embed, show_progress\u001b[39m=\u001b[39;49mshow_progress\n\u001b[0;32m    139\u001b[0m )\n\u001b[0;32m    141\u001b[0m \u001b[39mfor\u001b[39;00m new_id, text_embedding \u001b[39min\u001b[39;00m \u001b[39mzip\u001b[39m(ids_to_embed, new_embeddings):\n\u001b[0;32m    142\u001b[0m     id_to_embed_map[new_id] \u001b[39m=\u001b[39m text_embedding\n",
      "File \u001b[1;32mc:\\Users\\dt\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\llama_index\\embeddings\\base.py:255\u001b[0m, in \u001b[0;36mBaseEmbedding.get_text_embedding_batch\u001b[1;34m(self, texts, show_progress, **kwargs)\u001b[0m\n\u001b[0;32m    249\u001b[0m \u001b[39mif\u001b[39;00m idx \u001b[39m==\u001b[39m \u001b[39mlen\u001b[39m(texts) \u001b[39m-\u001b[39m \u001b[39m1\u001b[39m \u001b[39mor\u001b[39;00m \u001b[39mlen\u001b[39m(cur_batch) \u001b[39m==\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39membed_batch_size:\n\u001b[0;32m    250\u001b[0m     \u001b[39m# flush\u001b[39;00m\n\u001b[0;32m    251\u001b[0m     \u001b[39mwith\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcallback_manager\u001b[39m.\u001b[39mevent(\n\u001b[0;32m    252\u001b[0m         CBEventType\u001b[39m.\u001b[39mEMBEDDING,\n\u001b[0;32m    253\u001b[0m         payload\u001b[39m=\u001b[39m{EventPayload\u001b[39m.\u001b[39mSERIALIZED: \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mto_dict()},\n\u001b[0;32m    254\u001b[0m     ) \u001b[39mas\u001b[39;00m event:\n\u001b[1;32m--> 255\u001b[0m         embeddings \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_get_text_embeddings(cur_batch)\n\u001b[0;32m    256\u001b[0m         result_embeddings\u001b[39m.\u001b[39mextend(embeddings)\n\u001b[0;32m    257\u001b[0m         event\u001b[39m.\u001b[39mon_end(\n\u001b[0;32m    258\u001b[0m             payload\u001b[39m=\u001b[39m{\n\u001b[0;32m    259\u001b[0m                 EventPayload\u001b[39m.\u001b[39mCHUNKS: cur_batch,\n\u001b[0;32m    260\u001b[0m                 EventPayload\u001b[39m.\u001b[39mEMBEDDINGS: embeddings,\n\u001b[0;32m    261\u001b[0m             },\n\u001b[0;32m    262\u001b[0m         )\n",
      "File \u001b[1;32mc:\\Users\\dt\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\llama_index\\embeddings\\openai.py:360\u001b[0m, in \u001b[0;36mOpenAIEmbedding._get_text_embeddings\u001b[1;34m(self, texts)\u001b[0m\n\u001b[0;32m    353\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_get_text_embeddings\u001b[39m(\u001b[39mself\u001b[39m, texts: List[\u001b[39mstr\u001b[39m]) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m List[List[\u001b[39mfloat\u001b[39m]]:\n\u001b[0;32m    354\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"Get text embeddings.\u001b[39;00m\n\u001b[0;32m    355\u001b[0m \n\u001b[0;32m    356\u001b[0m \u001b[39m    By default, this is a wrapper around _get_text_embedding.\u001b[39;00m\n\u001b[0;32m    357\u001b[0m \u001b[39m    Can be overridden for batch queries.\u001b[39;00m\n\u001b[0;32m    358\u001b[0m \n\u001b[0;32m    359\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 360\u001b[0m     \u001b[39mreturn\u001b[39;00m get_embeddings(\n\u001b[0;32m    361\u001b[0m         \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_client,\n\u001b[0;32m    362\u001b[0m         texts,\n\u001b[0;32m    363\u001b[0m         engine\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_text_engine,\n\u001b[0;32m    364\u001b[0m         \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49madditional_kwargs,\n\u001b[0;32m    365\u001b[0m     )\n",
      "File \u001b[1;32mc:\\Users\\dt\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\tenacity\\__init__.py:289\u001b[0m, in \u001b[0;36mBaseRetrying.wraps.<locals>.wrapped_f\u001b[1;34m(*args, **kw)\u001b[0m\n\u001b[0;32m    287\u001b[0m \u001b[39m@functools\u001b[39m\u001b[39m.\u001b[39mwraps(f)\n\u001b[0;32m    288\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mwrapped_f\u001b[39m(\u001b[39m*\u001b[39margs: t\u001b[39m.\u001b[39mAny, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkw: t\u001b[39m.\u001b[39mAny) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m t\u001b[39m.\u001b[39mAny:\n\u001b[1;32m--> 289\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m(f, \u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkw)\n",
      "File \u001b[1;32mc:\\Users\\dt\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\tenacity\\__init__.py:379\u001b[0m, in \u001b[0;36mRetrying.__call__\u001b[1;34m(self, fn, *args, **kwargs)\u001b[0m\n\u001b[0;32m    377\u001b[0m retry_state \u001b[39m=\u001b[39m RetryCallState(retry_object\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m, fn\u001b[39m=\u001b[39mfn, args\u001b[39m=\u001b[39margs, kwargs\u001b[39m=\u001b[39mkwargs)\n\u001b[0;32m    378\u001b[0m \u001b[39mwhile\u001b[39;00m \u001b[39mTrue\u001b[39;00m:\n\u001b[1;32m--> 379\u001b[0m     do \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49miter(retry_state\u001b[39m=\u001b[39;49mretry_state)\n\u001b[0;32m    380\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(do, DoAttempt):\n\u001b[0;32m    381\u001b[0m         \u001b[39mtry\u001b[39;00m:\n",
      "File \u001b[1;32mc:\\Users\\dt\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\tenacity\\__init__.py:325\u001b[0m, in \u001b[0;36mBaseRetrying.iter\u001b[1;34m(self, retry_state)\u001b[0m\n\u001b[0;32m    323\u001b[0m     retry_exc \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mretry_error_cls(fut)\n\u001b[0;32m    324\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mreraise:\n\u001b[1;32m--> 325\u001b[0m         \u001b[39mraise\u001b[39;00m retry_exc\u001b[39m.\u001b[39;49mreraise()\n\u001b[0;32m    326\u001b[0m     \u001b[39mraise\u001b[39;00m retry_exc \u001b[39mfrom\u001b[39;00m \u001b[39mfut\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mexception\u001b[39;00m()\n\u001b[0;32m    328\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mwait:\n",
      "File \u001b[1;32mc:\\Users\\dt\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\tenacity\\__init__.py:158\u001b[0m, in \u001b[0;36mRetryError.reraise\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    156\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mreraise\u001b[39m(\u001b[39mself\u001b[39m) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m t\u001b[39m.\u001b[39mNoReturn:\n\u001b[0;32m    157\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mlast_attempt\u001b[39m.\u001b[39mfailed:\n\u001b[1;32m--> 158\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mlast_attempt\u001b[39m.\u001b[39;49mresult()\n\u001b[0;32m    159\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mself\u001b[39m\n",
      "File \u001b[1;32mc:\\Users\\dt\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\concurrent\\futures\\_base.py:449\u001b[0m, in \u001b[0;36mFuture.result\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m    447\u001b[0m     \u001b[39mraise\u001b[39;00m CancelledError()\n\u001b[0;32m    448\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_state \u001b[39m==\u001b[39m FINISHED:\n\u001b[1;32m--> 449\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m__get_result()\n\u001b[0;32m    451\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_condition\u001b[39m.\u001b[39mwait(timeout)\n\u001b[0;32m    453\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_state \u001b[39min\u001b[39;00m [CANCELLED, CANCELLED_AND_NOTIFIED]:\n",
      "File \u001b[1;32mc:\\Users\\dt\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\concurrent\\futures\\_base.py:401\u001b[0m, in \u001b[0;36mFuture.__get_result\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    399\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_exception:\n\u001b[0;32m    400\u001b[0m     \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m--> 401\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_exception\n\u001b[0;32m    402\u001b[0m     \u001b[39mfinally\u001b[39;00m:\n\u001b[0;32m    403\u001b[0m         \u001b[39m# Break a reference cycle with the exception in self._exception\u001b[39;00m\n\u001b[0;32m    404\u001b[0m         \u001b[39mself\u001b[39m \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\dt\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\tenacity\\__init__.py:382\u001b[0m, in \u001b[0;36mRetrying.__call__\u001b[1;34m(self, fn, *args, **kwargs)\u001b[0m\n\u001b[0;32m    380\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(do, DoAttempt):\n\u001b[0;32m    381\u001b[0m     \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m--> 382\u001b[0m         result \u001b[39m=\u001b[39m fn(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[0;32m    383\u001b[0m     \u001b[39mexcept\u001b[39;00m \u001b[39mBaseException\u001b[39;00m:  \u001b[39m# noqa: B902\u001b[39;00m\n\u001b[0;32m    384\u001b[0m         retry_state\u001b[39m.\u001b[39mset_exception(sys\u001b[39m.\u001b[39mexc_info())  \u001b[39m# type: ignore[arg-type]\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\dt\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\llama_index\\embeddings\\openai.py:162\u001b[0m, in \u001b[0;36mget_embeddings\u001b[1;34m(client, list_of_text, engine, **kwargs)\u001b[0m\n\u001b[0;32m    158\u001b[0m \u001b[39massert\u001b[39;00m \u001b[39mlen\u001b[39m(list_of_text) \u001b[39m<\u001b[39m\u001b[39m=\u001b[39m \u001b[39m2048\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mThe batch size should not be larger than 2048.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    160\u001b[0m list_of_text \u001b[39m=\u001b[39m [text\u001b[39m.\u001b[39mreplace(\u001b[39m\"\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39m \u001b[39m\u001b[39m\"\u001b[39m) \u001b[39mfor\u001b[39;00m text \u001b[39min\u001b[39;00m list_of_text]\n\u001b[1;32m--> 162\u001b[0m data \u001b[39m=\u001b[39m client\u001b[39m.\u001b[39;49membeddings\u001b[39m.\u001b[39;49mcreate(\u001b[39minput\u001b[39;49m\u001b[39m=\u001b[39;49mlist_of_text, model\u001b[39m=\u001b[39;49mengine, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\u001b[39m.\u001b[39mdata\n\u001b[0;32m    163\u001b[0m \u001b[39mreturn\u001b[39;00m [d\u001b[39m.\u001b[39membedding \u001b[39mfor\u001b[39;00m d \u001b[39min\u001b[39;00m data]\n",
      "File \u001b[1;32mc:\\Users\\dt\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\openai\\resources\\embeddings.py:105\u001b[0m, in \u001b[0;36mEmbeddings.create\u001b[1;34m(self, input, model, encoding_format, user, extra_headers, extra_query, extra_body, timeout)\u001b[0m\n\u001b[0;32m     99\u001b[0m         embedding\u001b[39m.\u001b[39membedding \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39mfrombuffer(  \u001b[39m# type: ignore[no-untyped-call]\u001b[39;00m\n\u001b[0;32m    100\u001b[0m             base64\u001b[39m.\u001b[39mb64decode(data), dtype\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mfloat32\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    101\u001b[0m         )\u001b[39m.\u001b[39mtolist()\n\u001b[0;32m    103\u001b[0m     \u001b[39mreturn\u001b[39;00m obj\n\u001b[1;32m--> 105\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_post(\n\u001b[0;32m    106\u001b[0m     \u001b[39m\"\u001b[39;49m\u001b[39m/embeddings\u001b[39;49m\u001b[39m\"\u001b[39;49m,\n\u001b[0;32m    107\u001b[0m     body\u001b[39m=\u001b[39;49mmaybe_transform(params, embedding_create_params\u001b[39m.\u001b[39;49mEmbeddingCreateParams),\n\u001b[0;32m    108\u001b[0m     options\u001b[39m=\u001b[39;49mmake_request_options(\n\u001b[0;32m    109\u001b[0m         extra_headers\u001b[39m=\u001b[39;49mextra_headers,\n\u001b[0;32m    110\u001b[0m         extra_query\u001b[39m=\u001b[39;49mextra_query,\n\u001b[0;32m    111\u001b[0m         extra_body\u001b[39m=\u001b[39;49mextra_body,\n\u001b[0;32m    112\u001b[0m         timeout\u001b[39m=\u001b[39;49mtimeout,\n\u001b[0;32m    113\u001b[0m         post_parser\u001b[39m=\u001b[39;49mparser,\n\u001b[0;32m    114\u001b[0m     ),\n\u001b[0;32m    115\u001b[0m     cast_to\u001b[39m=\u001b[39;49mCreateEmbeddingResponse,\n\u001b[0;32m    116\u001b[0m )\n",
      "File \u001b[1;32mc:\\Users\\dt\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\openai\\_base_client.py:1096\u001b[0m, in \u001b[0;36mSyncAPIClient.post\u001b[1;34m(self, path, cast_to, body, options, files, stream, stream_cls)\u001b[0m\n\u001b[0;32m   1082\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mpost\u001b[39m(\n\u001b[0;32m   1083\u001b[0m     \u001b[39mself\u001b[39m,\n\u001b[0;32m   1084\u001b[0m     path: \u001b[39mstr\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1091\u001b[0m     stream_cls: \u001b[39mtype\u001b[39m[_StreamT] \u001b[39m|\u001b[39m \u001b[39mNone\u001b[39;00m \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m,\n\u001b[0;32m   1092\u001b[0m ) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m ResponseT \u001b[39m|\u001b[39m _StreamT:\n\u001b[0;32m   1093\u001b[0m     opts \u001b[39m=\u001b[39m FinalRequestOptions\u001b[39m.\u001b[39mconstruct(\n\u001b[0;32m   1094\u001b[0m         method\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mpost\u001b[39m\u001b[39m\"\u001b[39m, url\u001b[39m=\u001b[39mpath, json_data\u001b[39m=\u001b[39mbody, files\u001b[39m=\u001b[39mto_httpx_files(files), \u001b[39m*\u001b[39m\u001b[39m*\u001b[39moptions\n\u001b[0;32m   1095\u001b[0m     )\n\u001b[1;32m-> 1096\u001b[0m     \u001b[39mreturn\u001b[39;00m cast(ResponseT, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mrequest(cast_to, opts, stream\u001b[39m=\u001b[39;49mstream, stream_cls\u001b[39m=\u001b[39;49mstream_cls))\n",
      "File \u001b[1;32mc:\\Users\\dt\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\openai\\_base_client.py:856\u001b[0m, in \u001b[0;36mSyncAPIClient.request\u001b[1;34m(self, cast_to, options, remaining_retries, stream, stream_cls)\u001b[0m\n\u001b[0;32m    847\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mrequest\u001b[39m(\n\u001b[0;32m    848\u001b[0m     \u001b[39mself\u001b[39m,\n\u001b[0;32m    849\u001b[0m     cast_to: Type[ResponseT],\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    854\u001b[0m     stream_cls: \u001b[39mtype\u001b[39m[_StreamT] \u001b[39m|\u001b[39m \u001b[39mNone\u001b[39;00m \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m,\n\u001b[0;32m    855\u001b[0m ) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m ResponseT \u001b[39m|\u001b[39m _StreamT:\n\u001b[1;32m--> 856\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_request(\n\u001b[0;32m    857\u001b[0m         cast_to\u001b[39m=\u001b[39;49mcast_to,\n\u001b[0;32m    858\u001b[0m         options\u001b[39m=\u001b[39;49moptions,\n\u001b[0;32m    859\u001b[0m         stream\u001b[39m=\u001b[39;49mstream,\n\u001b[0;32m    860\u001b[0m         stream_cls\u001b[39m=\u001b[39;49mstream_cls,\n\u001b[0;32m    861\u001b[0m         remaining_retries\u001b[39m=\u001b[39;49mremaining_retries,\n\u001b[0;32m    862\u001b[0m     )\n",
      "File \u001b[1;32mc:\\Users\\dt\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\openai\\_base_client.py:894\u001b[0m, in \u001b[0;36mSyncAPIClient._request\u001b[1;34m(self, cast_to, options, remaining_retries, stream, stream_cls)\u001b[0m\n\u001b[0;32m    892\u001b[0m \u001b[39mif\u001b[39;00m retries \u001b[39m>\u001b[39m \u001b[39m0\u001b[39m \u001b[39mand\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_should_retry(err\u001b[39m.\u001b[39mresponse):\n\u001b[0;32m    893\u001b[0m     err\u001b[39m.\u001b[39mresponse\u001b[39m.\u001b[39mclose()\n\u001b[1;32m--> 894\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_retry_request(\n\u001b[0;32m    895\u001b[0m         options,\n\u001b[0;32m    896\u001b[0m         cast_to,\n\u001b[0;32m    897\u001b[0m         retries,\n\u001b[0;32m    898\u001b[0m         err\u001b[39m.\u001b[39;49mresponse\u001b[39m.\u001b[39;49mheaders,\n\u001b[0;32m    899\u001b[0m         stream\u001b[39m=\u001b[39;49mstream,\n\u001b[0;32m    900\u001b[0m         stream_cls\u001b[39m=\u001b[39;49mstream_cls,\n\u001b[0;32m    901\u001b[0m     )\n\u001b[0;32m    903\u001b[0m \u001b[39m# If the response is streamed then we need to explicitly read the response\u001b[39;00m\n\u001b[0;32m    904\u001b[0m \u001b[39m# to completion before attempting to access the response text.\u001b[39;00m\n\u001b[0;32m    905\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m err\u001b[39m.\u001b[39mresponse\u001b[39m.\u001b[39mis_closed:\n",
      "File \u001b[1;32mc:\\Users\\dt\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\openai\\_base_client.py:966\u001b[0m, in \u001b[0;36mSyncAPIClient._retry_request\u001b[1;34m(self, options, cast_to, remaining_retries, response_headers, stream, stream_cls)\u001b[0m\n\u001b[0;32m    962\u001b[0m \u001b[39m# In a synchronous context we are blocking the entire thread. Up to the library user to run the client in a\u001b[39;00m\n\u001b[0;32m    963\u001b[0m \u001b[39m# different thread if necessary.\u001b[39;00m\n\u001b[0;32m    964\u001b[0m time\u001b[39m.\u001b[39msleep(timeout)\n\u001b[1;32m--> 966\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_request(\n\u001b[0;32m    967\u001b[0m     options\u001b[39m=\u001b[39;49moptions,\n\u001b[0;32m    968\u001b[0m     cast_to\u001b[39m=\u001b[39;49mcast_to,\n\u001b[0;32m    969\u001b[0m     remaining_retries\u001b[39m=\u001b[39;49mremaining,\n\u001b[0;32m    970\u001b[0m     stream\u001b[39m=\u001b[39;49mstream,\n\u001b[0;32m    971\u001b[0m     stream_cls\u001b[39m=\u001b[39;49mstream_cls,\n\u001b[0;32m    972\u001b[0m )\n",
      "File \u001b[1;32mc:\\Users\\dt\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\openai\\_base_client.py:894\u001b[0m, in \u001b[0;36mSyncAPIClient._request\u001b[1;34m(self, cast_to, options, remaining_retries, stream, stream_cls)\u001b[0m\n\u001b[0;32m    892\u001b[0m \u001b[39mif\u001b[39;00m retries \u001b[39m>\u001b[39m \u001b[39m0\u001b[39m \u001b[39mand\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_should_retry(err\u001b[39m.\u001b[39mresponse):\n\u001b[0;32m    893\u001b[0m     err\u001b[39m.\u001b[39mresponse\u001b[39m.\u001b[39mclose()\n\u001b[1;32m--> 894\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_retry_request(\n\u001b[0;32m    895\u001b[0m         options,\n\u001b[0;32m    896\u001b[0m         cast_to,\n\u001b[0;32m    897\u001b[0m         retries,\n\u001b[0;32m    898\u001b[0m         err\u001b[39m.\u001b[39;49mresponse\u001b[39m.\u001b[39;49mheaders,\n\u001b[0;32m    899\u001b[0m         stream\u001b[39m=\u001b[39;49mstream,\n\u001b[0;32m    900\u001b[0m         stream_cls\u001b[39m=\u001b[39;49mstream_cls,\n\u001b[0;32m    901\u001b[0m     )\n\u001b[0;32m    903\u001b[0m \u001b[39m# If the response is streamed then we need to explicitly read the response\u001b[39;00m\n\u001b[0;32m    904\u001b[0m \u001b[39m# to completion before attempting to access the response text.\u001b[39;00m\n\u001b[0;32m    905\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m err\u001b[39m.\u001b[39mresponse\u001b[39m.\u001b[39mis_closed:\n",
      "File \u001b[1;32mc:\\Users\\dt\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\openai\\_base_client.py:966\u001b[0m, in \u001b[0;36mSyncAPIClient._retry_request\u001b[1;34m(self, options, cast_to, remaining_retries, response_headers, stream, stream_cls)\u001b[0m\n\u001b[0;32m    962\u001b[0m \u001b[39m# In a synchronous context we are blocking the entire thread. Up to the library user to run the client in a\u001b[39;00m\n\u001b[0;32m    963\u001b[0m \u001b[39m# different thread if necessary.\u001b[39;00m\n\u001b[0;32m    964\u001b[0m time\u001b[39m.\u001b[39msleep(timeout)\n\u001b[1;32m--> 966\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_request(\n\u001b[0;32m    967\u001b[0m     options\u001b[39m=\u001b[39;49moptions,\n\u001b[0;32m    968\u001b[0m     cast_to\u001b[39m=\u001b[39;49mcast_to,\n\u001b[0;32m    969\u001b[0m     remaining_retries\u001b[39m=\u001b[39;49mremaining,\n\u001b[0;32m    970\u001b[0m     stream\u001b[39m=\u001b[39;49mstream,\n\u001b[0;32m    971\u001b[0m     stream_cls\u001b[39m=\u001b[39;49mstream_cls,\n\u001b[0;32m    972\u001b[0m )\n",
      "    \u001b[1;31m[... skipping similar frames: SyncAPIClient._request at line 894 (7 times), SyncAPIClient._retry_request at line 966 (7 times)]\u001b[0m\n",
      "File \u001b[1;32mc:\\Users\\dt\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\openai\\_base_client.py:894\u001b[0m, in \u001b[0;36mSyncAPIClient._request\u001b[1;34m(self, cast_to, options, remaining_retries, stream, stream_cls)\u001b[0m\n\u001b[0;32m    892\u001b[0m \u001b[39mif\u001b[39;00m retries \u001b[39m>\u001b[39m \u001b[39m0\u001b[39m \u001b[39mand\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_should_retry(err\u001b[39m.\u001b[39mresponse):\n\u001b[0;32m    893\u001b[0m     err\u001b[39m.\u001b[39mresponse\u001b[39m.\u001b[39mclose()\n\u001b[1;32m--> 894\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_retry_request(\n\u001b[0;32m    895\u001b[0m         options,\n\u001b[0;32m    896\u001b[0m         cast_to,\n\u001b[0;32m    897\u001b[0m         retries,\n\u001b[0;32m    898\u001b[0m         err\u001b[39m.\u001b[39;49mresponse\u001b[39m.\u001b[39;49mheaders,\n\u001b[0;32m    899\u001b[0m         stream\u001b[39m=\u001b[39;49mstream,\n\u001b[0;32m    900\u001b[0m         stream_cls\u001b[39m=\u001b[39;49mstream_cls,\n\u001b[0;32m    901\u001b[0m     )\n\u001b[0;32m    903\u001b[0m \u001b[39m# If the response is streamed then we need to explicitly read the response\u001b[39;00m\n\u001b[0;32m    904\u001b[0m \u001b[39m# to completion before attempting to access the response text.\u001b[39;00m\n\u001b[0;32m    905\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m err\u001b[39m.\u001b[39mresponse\u001b[39m.\u001b[39mis_closed:\n",
      "File \u001b[1;32mc:\\Users\\dt\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\openai\\_base_client.py:966\u001b[0m, in \u001b[0;36mSyncAPIClient._retry_request\u001b[1;34m(self, options, cast_to, remaining_retries, response_headers, stream, stream_cls)\u001b[0m\n\u001b[0;32m    962\u001b[0m \u001b[39m# In a synchronous context we are blocking the entire thread. Up to the library user to run the client in a\u001b[39;00m\n\u001b[0;32m    963\u001b[0m \u001b[39m# different thread if necessary.\u001b[39;00m\n\u001b[0;32m    964\u001b[0m time\u001b[39m.\u001b[39msleep(timeout)\n\u001b[1;32m--> 966\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_request(\n\u001b[0;32m    967\u001b[0m     options\u001b[39m=\u001b[39;49moptions,\n\u001b[0;32m    968\u001b[0m     cast_to\u001b[39m=\u001b[39;49mcast_to,\n\u001b[0;32m    969\u001b[0m     remaining_retries\u001b[39m=\u001b[39;49mremaining,\n\u001b[0;32m    970\u001b[0m     stream\u001b[39m=\u001b[39;49mstream,\n\u001b[0;32m    971\u001b[0m     stream_cls\u001b[39m=\u001b[39;49mstream_cls,\n\u001b[0;32m    972\u001b[0m )\n",
      "File \u001b[1;32mc:\\Users\\dt\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\openai\\_base_client.py:908\u001b[0m, in \u001b[0;36mSyncAPIClient._request\u001b[1;34m(self, cast_to, options, remaining_retries, stream, stream_cls)\u001b[0m\n\u001b[0;32m    905\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m err\u001b[39m.\u001b[39mresponse\u001b[39m.\u001b[39mis_closed:\n\u001b[0;32m    906\u001b[0m         err\u001b[39m.\u001b[39mresponse\u001b[39m.\u001b[39mread()\n\u001b[1;32m--> 908\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_make_status_error_from_response(err\u001b[39m.\u001b[39mresponse) \u001b[39mfrom\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m    909\u001b[0m \u001b[39mexcept\u001b[39;00m httpx\u001b[39m.\u001b[39mTimeoutException \u001b[39mas\u001b[39;00m err:\n\u001b[0;32m    910\u001b[0m     \u001b[39mif\u001b[39;00m response \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n",
      "\u001b[1;31mRateLimitError\u001b[0m: Error code: 429 - {'error': {'message': 'You exceeded your current quota, please check your plan and billing details.', 'type': 'insufficient_quota', 'param': None, 'code': 'insufficient_quota'}}"
     ]
    }
   ],
   "source": [
    "from llama_index.indices.multi_modal.base import MultiModalVectorStoreIndex\n",
    "from llama_index.node_parser import SentenceSplitter\n",
    "\n",
    "node_parser = SentenceSplitter.from_defaults()\n",
    "image_nodes = node_parser.get_nodes_from_documents(image_documents)\n",
    "text_nodes = node_parser.get_nodes_from_documents(text_documents)\n",
    "\n",
    "asl_index = MultiModalVectorStoreIndex(image_nodes + text_nodes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import FuyuProcessor, FuyuForCausalLM\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "Using `low_cpu_mem_usage=True` or a `device_map` requires Accelerate: `pip install accelerate`",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\dt\\Desktop\\Ayesha\\SPROUT\\multimodalsearch.ipynb Cell 8\u001b[0m line \u001b[0;36m4\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/dt/Desktop/Ayesha/SPROUT/multimodalsearch.ipynb#X10sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m model_id \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39madept/fuyu-8b\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/dt/Desktop/Ayesha/SPROUT/multimodalsearch.ipynb#X10sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m processor \u001b[39m=\u001b[39m FuyuProcessor\u001b[39m.\u001b[39mfrom_pretrained(model_id)\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/dt/Desktop/Ayesha/SPROUT/multimodalsearch.ipynb#X10sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m model \u001b[39m=\u001b[39m FuyuForCausalLM\u001b[39m.\u001b[39;49mfrom_pretrained(model_id, device_map\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mcuda:0\u001b[39;49m\u001b[39m\"\u001b[39;49m)\n",
      "File \u001b[1;32mc:\\Users\\dt\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\transformers\\modeling_utils.py:2674\u001b[0m, in \u001b[0;36mPreTrainedModel.from_pretrained\u001b[1;34m(cls, pretrained_model_name_or_path, config, cache_dir, ignore_mismatched_sizes, force_download, local_files_only, token, revision, use_safetensors, *model_args, **kwargs)\u001b[0m\n\u001b[0;32m   2670\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[0;32m   2671\u001b[0m             \u001b[39m\"\u001b[39m\u001b[39mDeepSpeed Zero-3 is not compatible with `low_cpu_mem_usage=True` or with passing a `device_map`.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m   2672\u001b[0m         )\n\u001b[0;32m   2673\u001b[0m     \u001b[39melif\u001b[39;00m \u001b[39mnot\u001b[39;00m is_accelerate_available():\n\u001b[1;32m-> 2674\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mImportError\u001b[39;00m(\n\u001b[0;32m   2675\u001b[0m             \u001b[39m\"\u001b[39m\u001b[39mUsing `low_cpu_mem_usage=True` or a `device_map` requires Accelerate: `pip install accelerate`\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m   2676\u001b[0m         )\n\u001b[0;32m   2678\u001b[0m quantization_method_from_args \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m   2679\u001b[0m \u001b[39mif\u001b[39;00m quantization_config \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n",
      "\u001b[1;31mImportError\u001b[0m: Using `low_cpu_mem_usage=True` or a `device_map` requires Accelerate: `pip install accelerate`"
     ]
    }
   ],
   "source": [
    "# load model and processor\n",
    "model_id = \"adept/fuyu-8b\"\n",
    "processor = FuyuProcessor.from_pretrained(model_id)\n",
    "model = FuyuForCausalLM.from_pretrained(model_id, device_map=\"cuda:0\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
